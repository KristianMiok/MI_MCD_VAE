{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EHB_Masking_Medical_Dataset_Cross.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdT9BTrmT3ro",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNUpL6YT32X",
        "colab_type": "code",
        "outputId": "f1866945-bdaf-4fde-d2be-890fc0ac4a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import set_random_seed\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.layers import Lambda, Input, Dense, Dropout\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.objectives import mse\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dropout, Dense\n",
        "from keras.regularizers import l1, l2\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from collections import defaultdict\n",
        "\n",
        "GLOBAL_SEED = 1\n",
        "LOCAL_SEED = 42\n",
        "\n",
        "set_random_seed(GLOBAL_SEED)\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "random.seed(GLOBAL_SEED)\n",
        "%matplotlib inline\n",
        "%pylab inline\n",
        "rcParams['figure.figsize'] = [10, 8]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DjJAxu80AFW6"
      },
      "source": [
        "# Access Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4QUbkrWUl2L",
        "colab_type": "code",
        "outputId": "abeee907-b7c0-4907-c090-edcbc2e03344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Access to resources\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VTGWwfObeoT",
        "colab_type": "text"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFaXts2Ycg-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define PATH to file\n",
        "path = 'gdrive/My Drive/Dataset/date_ani_v4b.xlsx'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcE15dwhyaL",
        "colab_type": "code",
        "outputId": "e6eb2165-56ad-448e-bbb3-41b62591c7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "set_random_seed(GLOBAL_SEED)\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "random.seed(GLOBAL_SEED)\n",
        "import pandas as pd\n",
        "df = pd.read_excel(path)\n",
        "df = df.fillna(np.nan)\n",
        "print('Origin dataset:')                 \n",
        "print(df.head())\n",
        "df.rename(columns={'gras_prot':'gras prot'}, inplace=True)\n",
        "df.rename(columns={' NCS binar':'NCS binar'}, inplace=True)\n",
        "# df[' NCS binar'] = df[' NCS binar'].astype('category')\n",
        "df['NCS ordinal'] = df['NCS ordinal'].astype('category')\n",
        "# df.rename(columns={\"gras_prot\": \"gras prot\"})\n",
        "df = shuffle(df, random_state=GLOBAL_SEED)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Origin dataset:\n",
            "   ID      an  measure  ... NCS ordinal  Unnamed: 16  Unnamed: 17\n",
            "0   8  2012.0      1.0  ...         1.0          NaN          NaN\n",
            "1  54  2012.0      1.0  ...         1.0          NaN          NaN\n",
            "2  54  2012.0      2.0  ...         0.0          NaN          NaN\n",
            "3  54  2012.0      3.0  ...         1.0          NaN          NaN\n",
            "4  54  2012.0      4.0  ...         0.0          NaN          NaN\n",
            "\n",
            "[5 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6lMwRxZpKqUt"
      },
      "source": [
        "#Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b249b1e6-124c-4786-d38d-4b08403c4429",
        "id": "xzVK12HoKqUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13687 entries, 4003 to 13349\n",
            "Data columns (total 18 columns):\n",
            "ID             13686 non-null object\n",
            "an             13686 non-null float64\n",
            "measure        13686 non-null float64\n",
            "an_measure     13686 non-null object\n",
            "cant           13445 non-null float64\n",
            "caze           7675 non-null float64\n",
            "gras           13686 non-null float64\n",
            "lact           13686 non-null float64\n",
            "ncs            13686 non-null float64\n",
            "ph             12554 non-null float64\n",
            "prot           13686 non-null float64\n",
            "gras prot      13686 non-null float64\n",
            "sun            13686 non-null float64\n",
            "uree           12345 non-null float64\n",
            "NCS binar      13686 non-null float64\n",
            "NCS ordinal    13686 non-null category\n",
            "Unnamed: 16    0 non-null float64\n",
            "Unnamed: 17    1 non-null float64\n",
            "dtypes: category(1), float64(15), object(2)\n",
            "memory usage: 1.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDC5ZAJsynon",
        "colab_type": "text"
      },
      "source": [
        "#### Infos\n",
        "\n",
        "THe ID do not contribute info --> Remove\n",
        "\n",
        "The an_measure and an columns have the same characteristics --> keep 1 (an_measure)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln3PCl5kqPQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['Unnamed: 16', 'Unnamed: 17', \n",
        "         'ID', 'an', 'an_measure',\n",
        "        #  ' NCS binar', \n",
        "         'NCS ordinal',\n",
        "         'measure'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSvIQv4lq3RF",
        "colab_type": "code",
        "outputId": "7a37f6c3-43de-48f7-967b-0dd499bd49cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13687 entries, 4003 to 13349\n",
            "Data columns (total 11 columns):\n",
            "cant         13445 non-null float64\n",
            "caze         7675 non-null float64\n",
            "gras         13686 non-null float64\n",
            "lact         13686 non-null float64\n",
            "ncs          13686 non-null float64\n",
            "ph           12554 non-null float64\n",
            "prot         13686 non-null float64\n",
            "gras prot    13686 non-null float64\n",
            "sun          13686 non-null float64\n",
            "uree         12345 non-null float64\n",
            "NCS binar    13686 non-null float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 1.3 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t1o4X8xYXKn",
        "colab_type": "code",
        "outputId": "9cb2455d-65e9-4070-be43-afab42d0cba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant</th>\n",
              "      <th>caze</th>\n",
              "      <th>gras</th>\n",
              "      <th>lact</th>\n",
              "      <th>ncs</th>\n",
              "      <th>ph</th>\n",
              "      <th>prot</th>\n",
              "      <th>gras prot</th>\n",
              "      <th>sun</th>\n",
              "      <th>uree</th>\n",
              "      <th>NCS binar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2.69</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.57</td>\n",
              "      <td>106.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.36</td>\n",
              "      <td>1.559524</td>\n",
              "      <td>8.60</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10445</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>5.49</td>\n",
              "      <td>4.73</td>\n",
              "      <td>4555.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.44</td>\n",
              "      <td>1.595930</td>\n",
              "      <td>8.88</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12002</th>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.82</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.29</td>\n",
              "      <td>1.471125</td>\n",
              "      <td>9.05</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5440</th>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.12</td>\n",
              "      <td>5.14</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.67</td>\n",
              "      <td>3.23</td>\n",
              "      <td>1.275542</td>\n",
              "      <td>9.22</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6034</th>\n",
              "      <td>9.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.73</td>\n",
              "      <td>4.65</td>\n",
              "      <td>157.0</td>\n",
              "      <td>6.61</td>\n",
              "      <td>3.38</td>\n",
              "      <td>1.399408</td>\n",
              "      <td>8.96</td>\n",
              "      <td>11.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cant  caze  gras  lact     ncs  ...  prot  gras prot   sun  uree  NCS binar\n",
              "4003   12.0  2.69  5.24  4.57   106.0  ...  3.36   1.559524  8.60   3.7        0.0\n",
              "10445   7.0  2.78  5.49  4.73  4555.0  ...  3.44   1.595930  8.88   3.5        1.0\n",
              "12002  11.0   NaN  4.84  4.82    17.0  ...  3.29   1.471125  9.05  23.2        0.0\n",
              "5440   10.0   NaN  4.12  5.14    17.0  ...  3.23   1.275542  9.22  30.3        0.0\n",
              "6034    9.9   NaN  4.73  4.65   157.0  ...  3.38   1.399408  8.96  11.4        0.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkHSrueZvyIm",
        "colab_type": "text"
      },
      "source": [
        "## Get the NULL data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILK6wlatKqVA",
        "colab": {}
      },
      "source": [
        "df_null = df[pd.isnull(df).any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R5kGDK-2KqVF",
        "outputId": "098d535c-cadc-4f1f-ddb9-1624c23cdd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df_null.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7590 entries, 12002 to 13349\n",
            "Data columns (total 11 columns):\n",
            "cant         7348 non-null float64\n",
            "caze         1578 non-null float64\n",
            "gras         7589 non-null float64\n",
            "lact         7589 non-null float64\n",
            "ncs          7589 non-null float64\n",
            "ph           6457 non-null float64\n",
            "prot         7589 non-null float64\n",
            "gras prot    7589 non-null float64\n",
            "sun          7589 non-null float64\n",
            "uree         6248 non-null float64\n",
            "NCS binar    7589 non-null float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 711.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uev-4Ei3v6fB",
        "colab_type": "code",
        "outputId": "dc61fc64-f118-48d6-9e37-9b75931f468e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "df_null.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant</th>\n",
              "      <th>caze</th>\n",
              "      <th>gras</th>\n",
              "      <th>lact</th>\n",
              "      <th>ncs</th>\n",
              "      <th>ph</th>\n",
              "      <th>prot</th>\n",
              "      <th>gras prot</th>\n",
              "      <th>sun</th>\n",
              "      <th>uree</th>\n",
              "      <th>NCS binar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7348.000000</td>\n",
              "      <td>1578.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>6457.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "      <td>6248.000000</td>\n",
              "      <td>7589.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.372047</td>\n",
              "      <td>0.778726</td>\n",
              "      <td>4.021916</td>\n",
              "      <td>4.761154</td>\n",
              "      <td>407.298195</td>\n",
              "      <td>6.576436</td>\n",
              "      <td>3.490543</td>\n",
              "      <td>1.157126</td>\n",
              "      <td>9.064051</td>\n",
              "      <td>18.030746</td>\n",
              "      <td>0.333641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.713735</td>\n",
              "      <td>1.258699</td>\n",
              "      <td>0.901370</td>\n",
              "      <td>0.239245</td>\n",
              "      <td>1064.194753</td>\n",
              "      <td>0.080871</td>\n",
              "      <td>0.484736</td>\n",
              "      <td>0.231477</td>\n",
              "      <td>0.479926</td>\n",
              "      <td>8.506621</td>\n",
              "      <td>0.471544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>2.560000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>2.050000</td>\n",
              "      <td>0.203540</td>\n",
              "      <td>6.860000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>4.660000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>6.530000</td>\n",
              "      <td>3.140000</td>\n",
              "      <td>1.023981</td>\n",
              "      <td>8.750000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.980000</td>\n",
              "      <td>4.790000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>6.580000</td>\n",
              "      <td>3.450000</td>\n",
              "      <td>1.154545</td>\n",
              "      <td>9.030000</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.340000</td>\n",
              "      <td>4.570000</td>\n",
              "      <td>4.910000</td>\n",
              "      <td>301.000000</td>\n",
              "      <td>6.620000</td>\n",
              "      <td>3.790000</td>\n",
              "      <td>1.290429</td>\n",
              "      <td>9.360000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17.400000</td>\n",
              "      <td>4.620000</td>\n",
              "      <td>8.930000</td>\n",
              "      <td>6.120000</td>\n",
              "      <td>23400.000000</td>\n",
              "      <td>7.650000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>2.545455</td>\n",
              "      <td>13.710000</td>\n",
              "      <td>76.800000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              cant         caze  ...         uree    NCS binar\n",
              "count  7348.000000  1578.000000  ...  6248.000000  7589.000000\n",
              "mean      8.372047     0.778726  ...    18.030746     0.333641\n",
              "std       2.713735     1.258699  ...     8.506621     0.471544\n",
              "min       1.500000     0.000000  ...     0.000000     0.000000\n",
              "25%       6.500000     0.000000  ...    11.600000     0.000000\n",
              "50%       8.200000     0.000000  ...    17.700000     0.000000\n",
              "75%      10.000000     2.340000  ...    24.000000     1.000000\n",
              "max      17.400000     4.620000  ...    76.800000     1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt5VQqV8v8r7",
        "colab_type": "code",
        "outputId": "28e8d6f6-69c8-4cbc-a4ed-7c0a70fd4875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "# NULL data histogram\n",
        "df_null.hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f470aa83630>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470b352550>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a63f400>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a62c5c0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a633eb8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a5ae710>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a5dda20>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a4b05c0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a4b0a20>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a551780>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a5156d8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470b39aa90>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAHiCAYAAABP+3CeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVlmTsDMzMzMMnMCZmZmZpbZ/wE2Q1uelarvCAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x576 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO6ZHH9Mv2Wk",
        "colab_type": "text"
      },
      "source": [
        "## Get the NON-NULL data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQW553c6uZP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_non_null = df[~pd.isnull(df).any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcC3e0quu9qj",
        "colab_type": "code",
        "outputId": "73171208-9d62-4c86-a4cb-c0343253bb4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df_non_null.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6097 entries, 4003 to 235\n",
            "Data columns (total 11 columns):\n",
            "cant         6097 non-null float64\n",
            "caze         6097 non-null float64\n",
            "gras         6097 non-null float64\n",
            "lact         6097 non-null float64\n",
            "ncs          6097 non-null float64\n",
            "ph           6097 non-null float64\n",
            "prot         6097 non-null float64\n",
            "gras prot    6097 non-null float64\n",
            "sun          6097 non-null float64\n",
            "uree         6097 non-null float64\n",
            "NCS binar    6097 non-null float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 571.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCaBzHVnvEPD",
        "colab_type": "code",
        "outputId": "f3d97cf5-fdb7-41c1-97f3-a163559e61e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "df_non_null.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant</th>\n",
              "      <th>caze</th>\n",
              "      <th>gras</th>\n",
              "      <th>lact</th>\n",
              "      <th>ncs</th>\n",
              "      <th>ph</th>\n",
              "      <th>prot</th>\n",
              "      <th>gras prot</th>\n",
              "      <th>sun</th>\n",
              "      <th>uree</th>\n",
              "      <th>NCS binar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.00000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "      <td>6097.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.711940</td>\n",
              "      <td>2.225511</td>\n",
              "      <td>4.093354</td>\n",
              "      <td>4.698296</td>\n",
              "      <td>433.93341</td>\n",
              "      <td>6.582782</td>\n",
              "      <td>3.518242</td>\n",
              "      <td>1.168295</td>\n",
              "      <td>9.014404</td>\n",
              "      <td>20.248106</td>\n",
              "      <td>0.331146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.661818</td>\n",
              "      <td>1.140497</td>\n",
              "      <td>0.932236</td>\n",
              "      <td>0.248591</td>\n",
              "      <td>1224.10183</td>\n",
              "      <td>0.125730</td>\n",
              "      <td>0.458590</td>\n",
              "      <td>0.245234</td>\n",
              "      <td>0.481920</td>\n",
              "      <td>11.422000</td>\n",
              "      <td>0.470664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>2.400000</td>\n",
              "      <td>2.00000</td>\n",
              "      <td>5.610000</td>\n",
              "      <td>2.140000</td>\n",
              "      <td>0.103535</td>\n",
              "      <td>6.800000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.270000</td>\n",
              "      <td>3.530000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>6.530000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>1.033113</td>\n",
              "      <td>8.710000</td>\n",
              "      <td>10.900000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.500000</td>\n",
              "      <td>2.640000</td>\n",
              "      <td>4.090000</td>\n",
              "      <td>4.730000</td>\n",
              "      <td>104.00000</td>\n",
              "      <td>6.590000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.168539</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>19.400000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.300000</td>\n",
              "      <td>2.920000</td>\n",
              "      <td>4.660000</td>\n",
              "      <td>4.850000</td>\n",
              "      <td>283.00000</td>\n",
              "      <td>6.640000</td>\n",
              "      <td>3.810000</td>\n",
              "      <td>1.304469</td>\n",
              "      <td>9.310000</td>\n",
              "      <td>28.200000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>5.420000</td>\n",
              "      <td>9.850000</td>\n",
              "      <td>8.310000</td>\n",
              "      <td>20796.00000</td>\n",
              "      <td>13.340000</td>\n",
              "      <td>7.110000</td>\n",
              "      <td>2.705036</td>\n",
              "      <td>16.940000</td>\n",
              "      <td>78.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              cant         caze  ...         uree    NCS binar\n",
              "count  6097.000000  6097.000000  ...  6097.000000  6097.000000\n",
              "mean      7.711940     2.225511  ...    20.248106     0.331146\n",
              "std       2.661818     1.140497  ...    11.422000     0.470664\n",
              "min       1.500000     0.000000  ...     0.100000     0.000000\n",
              "25%       6.000000     2.270000  ...    10.900000     0.000000\n",
              "50%       7.500000     2.640000  ...    19.400000     0.000000\n",
              "75%       9.300000     2.920000  ...    28.200000     1.000000\n",
              "max      19.000000     5.420000  ...    78.600000     1.000000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDxx8gxSwQcY",
        "colab_type": "code",
        "outputId": "0c1ff4f8-c5f5-4f08-e718-22ebd39c3a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "df_non_null.hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a92a208>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a703a90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a68bf28>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470aae34e0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470aae8a58>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a8e2fd0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a9ea588>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a9d5b38>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a9d5b70>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470a726630>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470a7455f8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470ad74160>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAHiCAYAAABP+3CeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwMzMzMxK5gKYmZmZWcn+PxipLuCnqUOnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqZCvdLWxSdE",
        "colab_type": "code",
        "outputId": "d707298a-ecf9-447d-aac4-22b4a25026b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "df_null.fillna(0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  downcast=downcast, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98cBy65XxwF_",
        "colab_type": "code",
        "outputId": "ba4dd79c-c313-4a15-b1c4-875286162e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        }
      },
      "source": [
        "df_null.hist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f470b1e3828>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470b05d668>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470b07dbe0>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470b02f198>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470afd5710>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470afffc88>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470afaf240>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470af577f0>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470af57828>],\n",
              "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f470af312e8>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470aed8860>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f470af01dd8>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAHiCAYAAABP+3CeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x576 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgMD90A_vtZ4",
        "colab_type": "text"
      },
      "source": [
        "#Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BTZmwBHIdVq",
        "colab_type": "code",
        "outputId": "0aedfeea-dc67-4e14-cbe7-49939746546a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant</th>\n",
              "      <th>caze</th>\n",
              "      <th>gras</th>\n",
              "      <th>lact</th>\n",
              "      <th>ncs</th>\n",
              "      <th>ph</th>\n",
              "      <th>prot</th>\n",
              "      <th>gras prot</th>\n",
              "      <th>sun</th>\n",
              "      <th>uree</th>\n",
              "      <th>NCS binar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2.69</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.57</td>\n",
              "      <td>106.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.36</td>\n",
              "      <td>1.559524</td>\n",
              "      <td>8.60</td>\n",
              "      <td>3.7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10445</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>5.49</td>\n",
              "      <td>4.73</td>\n",
              "      <td>4555.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.44</td>\n",
              "      <td>1.595930</td>\n",
              "      <td>8.88</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12002</th>\n",
              "      <td>11.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.82</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.29</td>\n",
              "      <td>1.471125</td>\n",
              "      <td>9.05</td>\n",
              "      <td>23.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5440</th>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.12</td>\n",
              "      <td>5.14</td>\n",
              "      <td>17.0</td>\n",
              "      <td>6.67</td>\n",
              "      <td>3.23</td>\n",
              "      <td>1.275542</td>\n",
              "      <td>9.22</td>\n",
              "      <td>30.3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6034</th>\n",
              "      <td>9.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.73</td>\n",
              "      <td>4.65</td>\n",
              "      <td>157.0</td>\n",
              "      <td>6.61</td>\n",
              "      <td>3.38</td>\n",
              "      <td>1.399408</td>\n",
              "      <td>8.96</td>\n",
              "      <td>11.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cant  caze  gras  lact     ncs  ...  prot  gras prot   sun  uree  NCS binar\n",
              "4003   12.0  2.69  5.24  4.57   106.0  ...  3.36   1.559524  8.60   3.7        0.0\n",
              "10445   7.0  2.78  5.49  4.73  4555.0  ...  3.44   1.595930  8.88   3.5        1.0\n",
              "12002  11.0   NaN  4.84  4.82    17.0  ...  3.29   1.471125  9.05  23.2        0.0\n",
              "5440   10.0   NaN  4.12  5.14    17.0  ...  3.23   1.275542  9.22  30.3        0.0\n",
              "6034    9.9   NaN  4.73  4.65   157.0  ...  3.38   1.399408  8.96  11.4        0.0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bz2G8ubqLqC",
        "colab_type": "code",
        "outputId": "31c67472-5dbd-43fb-8912-ad7d83590fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13687 entries, 4003 to 13349\n",
            "Data columns (total 11 columns):\n",
            "cant         13445 non-null float64\n",
            "caze         7675 non-null float64\n",
            "gras         13686 non-null float64\n",
            "lact         13686 non-null float64\n",
            "ncs          13686 non-null float64\n",
            "ph           12554 non-null float64\n",
            "prot         13686 non-null float64\n",
            "gras prot    13686 non-null float64\n",
            "sun          13686 non-null float64\n",
            "uree         12345 non-null float64\n",
            "NCS binar    13686 non-null float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 1.3 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gutSXkwNq5t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_null = df[pd.isnull(df).any(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwxa9qTHratZ",
        "colab_type": "code",
        "outputId": "83b48984-563c-4932-8a36-a0a7c88da2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df_null.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7590 entries, 12002 to 13349\n",
            "Data columns (total 11 columns):\n",
            "cant         7348 non-null float64\n",
            "caze         1578 non-null float64\n",
            "gras         7589 non-null float64\n",
            "lact         7589 non-null float64\n",
            "ncs          7589 non-null float64\n",
            "ph           6457 non-null float64\n",
            "prot         7589 non-null float64\n",
            "gras prot    7589 non-null float64\n",
            "sun          7589 non-null float64\n",
            "uree         6248 non-null float64\n",
            "NCS binar    7589 non-null float64\n",
            "dtypes: float64(11)\n",
            "memory usage: 711.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewCffjOEYmdy",
        "colab_type": "code",
        "outputId": "930a4b18-e255-4aae-d92d-5ff74644ecca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "df['NCS binar'] = df['NCS binar'].astype('category')\n",
        "df_non_null['NCS binar'] = df_non_null['NCS binar'].astype('category')\n",
        "cat_cols = ['NCS binar']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPps8ymcZPrk",
        "colab_type": "code",
        "outputId": "c560d1ff-ed94-4ab2-baac-1c2ba9bb7d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df_non_null.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6097 entries, 4003 to 235\n",
            "Data columns (total 11 columns):\n",
            "cant         6097 non-null float64\n",
            "caze         6097 non-null float64\n",
            "gras         6097 non-null float64\n",
            "lact         6097 non-null float64\n",
            "ncs          6097 non-null float64\n",
            "ph           6097 non-null float64\n",
            "prot         6097 non-null float64\n",
            "gras prot    6097 non-null float64\n",
            "sun          6097 non-null float64\n",
            "uree         6097 non-null float64\n",
            "NCS binar    6097 non-null category\n",
            "dtypes: category(1), float64(10)\n",
            "memory usage: 530.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRRZgCPE2WJS",
        "colab_type": "text"
      },
      "source": [
        "# Make data become missing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJBNlVLoJloq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "prob_missing = 0.3\n",
        "df_incomplete = df_non_null.copy()\n",
        "ix = [(row, col) for row in range(df_non_null.shape[0]) for col in range(df_non_null.shape[1])]\n",
        "L = resample(ix, n_samples = int(prob_missing*len(ix)), random_state=LOCAL_SEED)\n",
        "for row, col in L:\n",
        "    df_incomplete.iat[row, col] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDDT8QZXMZ9p",
        "colab_type": "code",
        "outputId": "f6567d6c-746b-4c34-92bd-06bbd45a3680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "df_incomplete.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6097 entries, 4003 to 235\n",
            "Data columns (total 11 columns):\n",
            "cant         5514 non-null float64\n",
            "caze         5511 non-null float64\n",
            "gras         5527 non-null float64\n",
            "lact         5540 non-null float64\n",
            "ncs          5534 non-null float64\n",
            "ph           5523 non-null float64\n",
            "prot         5530 non-null float64\n",
            "gras prot    5496 non-null float64\n",
            "sun          5511 non-null float64\n",
            "uree         5504 non-null float64\n",
            "NCS binar    5474 non-null category\n",
            "dtypes: category(1), float64(10)\n",
            "memory usage: 530.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDlflMKPZSn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_encoded = pd.get_dummies(df_incomplete)\n",
        "\n",
        "for col in df.columns:\n",
        "    missing_cols = missing_encoded.columns.str.startswith(str(col) + \"_\")\n",
        "    missing_encoded.loc[df_incomplete[col].isnull(), missing_cols] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntnenzc17rDV",
        "colab_type": "code",
        "outputId": "af597768-5d41-4265-f320-8c6526b535b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "missing_encoded.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cant</th>\n",
              "      <th>caze</th>\n",
              "      <th>gras</th>\n",
              "      <th>lact</th>\n",
              "      <th>ncs</th>\n",
              "      <th>ph</th>\n",
              "      <th>prot</th>\n",
              "      <th>gras prot</th>\n",
              "      <th>sun</th>\n",
              "      <th>uree</th>\n",
              "      <th>NCS binar_0.0</th>\n",
              "      <th>NCS binar_1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4003</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2.69</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.57</td>\n",
              "      <td>106.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.36</td>\n",
              "      <td>1.559524</td>\n",
              "      <td>8.60</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10445</th>\n",
              "      <td>7.0</td>\n",
              "      <td>2.78</td>\n",
              "      <td>5.49</td>\n",
              "      <td>4.73</td>\n",
              "      <td>4555.0</td>\n",
              "      <td>6.62</td>\n",
              "      <td>3.44</td>\n",
              "      <td>1.595930</td>\n",
              "      <td>8.88</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2063</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.97</td>\n",
              "      <td>4.83</td>\n",
              "      <td>158.0</td>\n",
              "      <td>6.61</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.121469</td>\n",
              "      <td>9.21</td>\n",
              "      <td>33.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6571</th>\n",
              "      <td>2.3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.42</td>\n",
              "      <td>4.29</td>\n",
              "      <td>634.0</td>\n",
              "      <td>6.54</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.096774</td>\n",
              "      <td>9.23</td>\n",
              "      <td>16.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3796</th>\n",
              "      <td>5.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.54</td>\n",
              "      <td>4.62</td>\n",
              "      <td>105.0</td>\n",
              "      <td>6.59</td>\n",
              "      <td>3.55</td>\n",
              "      <td>1.278873</td>\n",
              "      <td>9.10</td>\n",
              "      <td>28.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cant  caze  gras  lact  ...   sun  uree  NCS binar_0.0  NCS binar_1.0\n",
              "4003   12.0  2.69  5.24  4.57  ...  8.60   3.7            1.0            0.0\n",
              "10445   7.0  2.78  5.49  4.73  ...  8.88   3.5            0.0            1.0\n",
              "2063    7.0  0.00  3.97  4.83  ...  9.21  33.7            1.0            0.0\n",
              "6571    2.3  0.00  4.42  4.29  ...  9.23  16.1            0.0            1.0\n",
              "3796    5.7  0.00  4.54  4.62  ...  9.10  28.2            1.0            0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_7GuK_df_TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_size = 1000\n",
        "n_epochs = 100\n",
        "n_batch_size=1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dNiaTLkMxq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def masked_mae(X_true, X_pred, mask):\n",
        "    masked_diff = X_true[mask] - X_pred[mask]\n",
        "    return np.mean(np.abs(masked_diff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AF6didNfuiSp",
        "colab": {}
      },
      "source": [
        "def reverse_encoding(df_test_dummies):\n",
        "    names = list(df_test_dummies)\n",
        "    c_dict = {}\n",
        "    for n in names:\n",
        "        if '_' in n:\n",
        "            index = n.index('_')\n",
        "            c_dict[n[:index]] = [c for c in names if n[:index+1] in c]\n",
        "    values = []\n",
        "    for key, items in c_dict.items():\n",
        "        dummies = df_test_dummies[items]\n",
        "        d_names = list(dummies)\n",
        "        c_dict = {}\n",
        "        for n in d_names:\n",
        "            c_dict[n] = n[n.index('_')+1:]\n",
        "        dummies.rename(columns=c_dict, \n",
        "                    inplace=True)\n",
        "        df_test_dummies[key] = dummies.idxmax(axis=1)\n",
        "        df_test_dummies.drop(items, axis=1, inplace=True)\n",
        "    print(df_test_dummies.head())\n",
        "    return df_test_dummies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Eg6YJ1tvfP",
        "colab_type": "text"
      },
      "source": [
        "# AutoEncoder with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3BA-97jlmzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "values = missing_encoded.values.copy()\n",
        "train, test, comp_train, comp_test = train_test_split(values,\n",
        "                                                      df_non_null.values.copy(),\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=LOCAL_SEED)\n",
        "scaler = MinMaxScaler().fit(train)\n",
        "x_train = scaler.transform(train)\n",
        "x_test = scaler.transform(test)\n",
        "n_dims = x_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJyWx03VHfCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = df_non_null.columns\n",
        "df_test_complete = pd.DataFrame(columns=cols, \n",
        "                                data=comp_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j-GqCbvMptj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoEncoderDropout:\n",
        "    def __init__(self, \n",
        "                 n_dims,\n",
        "                 recurrent_weight=0.5,\n",
        "                 optimizer=\"adam\",\n",
        "                 dropout_probability=0.5,\n",
        "                 hidden_activation=\"relu\",\n",
        "                 output_activation=\"sigmoid\",\n",
        "                 init=\"glorot_normal\",\n",
        "                 l1_penalty=1e-3,\n",
        "                 l2_penalty=1e-3,\n",
        "                 hidden_size=hidden_size):\n",
        "        self.n_dims = n_dims\n",
        "        self.recurrent_weight = recurrent_weight\n",
        "        self.optimizer = optimizer\n",
        "        self.dropout_probability = dropout_probability\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "        self.init = init\n",
        "        self.l1_penalty = l1_penalty\n",
        "        self.l2_penalty = l2_penalty\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def make_reconstruction_loss(self, n_features):\n",
        "        def reconstruction_loss(input_and_mask, y_pred):\n",
        "            X_values = input_and_mask[:, :n_features]\n",
        "            missing_mask = input_and_mask[:, n_features:]\n",
        "            observed_mask = 1 - missing_mask\n",
        "            X_values_observed = X_values * observed_mask\n",
        "            pred_observed = y_pred * observed_mask\n",
        "            return binary_crossentropy(y_true=X_values_observed, \n",
        "                                       y_pred=pred_observed)\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _create_model(self):\n",
        "        latent_dim = int(np.ceil(self.n_dims*0.5))\n",
        "        inputs = Input(shape=(2*self.n_dims, ), \n",
        "                       name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        encoded = Dense(latent_dim, name='encoding')(x)\n",
        "        self.encoder = Model(inputs, encoded, name='encoder')\n",
        "        latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "        x = latent_inputs\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        outputs = Dense(self.n_dims, activation=self.output_activation,\n",
        "                        init=self.init,\n",
        "                        kernel_regularizer=l2(self.l2_penalty),\n",
        "                        bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs))\n",
        "        self.model = Model(inputs, outputs, name='ae_mlp')\n",
        "        loss_function = self.make_reconstruction_loss(self.n_dims)\n",
        "        self.model.compile(optimizer=self.optimizer, \n",
        "                           loss=loss_function)\n",
        "\n",
        "    def fill(self, data, missing_mask):\n",
        "        data[missing_mask] = -1\n",
        "        return data\n",
        "\n",
        "    def _create_missing_mask(self, data):\n",
        "        if data.dtype != \"f\" and data.dtype != \"d\":\n",
        "            data = data.astype(float)\n",
        "        return np.isnan(data)\n",
        "\n",
        "    def _train_epoch(self, data, missing_mask, batch_size):\n",
        "        input_with_mask = np.hstack([data, missing_mask])\n",
        "        n_samples = len(input_with_mask)\n",
        "        n_batches = int(np.ceil(n_samples / batch_size))\n",
        "        indices = np.arange(n_samples)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = input_with_mask[indices]\n",
        "        for batch_idx in range(n_batches):\n",
        "            batch_start = batch_idx * batch_size\n",
        "            batch_end = (batch_idx + 1) * batch_size\n",
        "            batch_data = X_shuffled[batch_start:batch_end, :]\n",
        "            self.model.train_on_batch(batch_data, batch_data)\n",
        "        return self.model.predict(input_with_mask)\n",
        "    \n",
        "    def predict(self, x_test_with_mask):\n",
        "        predict_stochastic = K.function([self.decoder.layers[0].input,\n",
        "                                        K.learning_phase()],\n",
        "                                        [self.decoder.layers[-1].output])\n",
        "        latent_input = self.encoder.predict(x_test_with_mask)\n",
        "\n",
        "        outputs = np.array([np.array(predict_stochastic([latent_input, \n",
        "                                                         1])).reshape((x_test_with_mask.shape[0], \n",
        "                                                                       x_test_with_mask.shape[1]//2)) for _ in range(50)])\n",
        "        return np.mean(outputs, axis=0)\n",
        "\n",
        "    def predict_dist(self, x_test, n_epochs=50):\n",
        "        predict_stochastic = K.function([self.decoder.layers[0].input,\n",
        "                                        K.learning_phase()],\n",
        "                                        [self.decoder.layers[-1].output])\n",
        "        x_test_missing_mask = self._create_missing_mask(x_test) \n",
        "        x_test = self.fill(x_test, x_test_missing_mask)\n",
        "        x_test_observed_mask = ~x_test_missing_mask\n",
        "        x_test_with_mask = np.hstack([x_test, x_test_missing_mask])\n",
        "        latent_input = self.encoder.predict(x_test_with_mask)\n",
        "        X_test_pred = np.array([predict_stochastic([latent_input, 1])])\n",
        "        X_test_pred = X_test_pred.reshape((x_test.shape[0], x_test.shape[1]))\n",
        "        print(X_test_pred.shape)\n",
        "        for _ in range(n_epochs):\n",
        "            old_weight = (1.0 - self.recurrent_weight)\n",
        "            x_test[x_test_missing_mask] *= old_weight\n",
        "            x_test_pred_missing = X_test_pred[x_test_missing_mask]\n",
        "            x_test[x_test_missing_mask] += self.recurrent_weight * x_test_pred_missing\n",
        "        return x_test\n",
        "\n",
        "    def train(self, x_train, x_test, batch_size=256, train_epochs=100):\n",
        "        missing_mask = self._create_missing_mask(x_train)\n",
        "        x_train = self.fill(x_train, missing_mask)\n",
        "        x_test_missing_mask = self._create_missing_mask(x_test) \n",
        "        x_test = self.fill(x_test, x_test_missing_mask)\n",
        "\n",
        "        self._create_model()\n",
        "        \n",
        "        observed_mask = ~missing_mask\n",
        "        x_test_observed_mask = ~x_test_missing_mask\n",
        "        input_with_mask = np.hstack([x_train, missing_mask])\n",
        "        for epoch in range(train_epochs):\n",
        "            X_pred = self._train_epoch(x_train, missing_mask, batch_size)\n",
        "            x_test_with_mask = np.hstack([x_test, x_test_missing_mask])\n",
        "            X_test_pred = self.predict(x_test_with_mask)\n",
        "            observed_mae = masked_mae(X_true=x_train,\n",
        "                                    X_pred=X_pred,\n",
        "                                    mask=observed_mask)\n",
        "            test_observed_mae = masked_mae(X_true=x_test,\n",
        "                                           X_pred = X_test_pred,\n",
        "                                           mask=x_test_observed_mask)\n",
        "            if epoch % 50 == 0:\n",
        "                print(\"observed mae:\", observed_mae)\n",
        "                print(\"Test mae:\", test_observed_mae)\n",
        "            old_weight = (1.0 - self.recurrent_weight)\n",
        "            x_train[missing_mask] *= old_weight\n",
        "            x_test[x_test_missing_mask] *= old_weight\n",
        "            pred_missing = X_pred[missing_mask]\n",
        "            x_test_pred_missing = X_test_pred[x_test_missing_mask]\n",
        "            x_train[missing_mask] += self.recurrent_weight * pred_missing\n",
        "            x_test[x_test_missing_mask] += self.recurrent_weight * x_test_pred_missing\n",
        "        return x_train.copy(), x_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8c72da28-3965-4d2f-82d0-cb9079357637",
        "id": "C6eZwyYLvp8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "seeds = [LOCAL_SEED+2, LOCAL_SEED+1, LOCAL_SEED+4, LOCAL_SEED+6, LOCAL_SEED+8]\n",
        "rmses = []\n",
        "cols = df_non_null.columns\n",
        "non_null_values = df_non_null.values.copy()\n",
        "for seed_number in seeds:\n",
        "    values = missing_encoded.values.copy()\n",
        "    train, test, comp_train, comp_test = train_test_split(values.copy(),\n",
        "                                                        non_null_values.copy(),\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=seed_number)\n",
        "    df_test_complete = pd.DataFrame(columns=cols, \n",
        "                                    data=comp_test.copy())\n",
        "    scaler = MinMaxScaler().fit(train)\n",
        "    x_train = scaler.transform(train)\n",
        "    x_test = scaler.transform(test)\n",
        "    n_dims = x_train.shape[1]\n",
        "    aedropout = AutoEncoderDropout(n_dims=n_dims)\n",
        "    complete_encoded = aedropout.train(x_train.copy(), \n",
        "                                    x_test.copy(), \n",
        "                                    train_epochs=n_epochs,\n",
        "                                    batch_size=n_batch_size)\n",
        "    train_encoded, test_encoded = complete_encoded\n",
        "    missing_cols = list(missing_encoded)\n",
        "    inverse_test_encoded = scaler.inverse_transform(test_encoded)\n",
        "    df_test_dummies = pd.DataFrame(columns=missing_cols, \n",
        "                                   data=inverse_test_encoded)\n",
        "    df_test_dummies = reverse_encoding(df_test_dummies.copy())\n",
        "    df_test_dummies.drop(cat_cols, axis=1,\n",
        "                         inplace=True)\n",
        "    df_test_complete.drop(cat_cols, axis=1,\n",
        "                          inplace=True)\n",
        "    true_vals = df_test_complete.values.copy()\n",
        "    test_vals = df_test_dummies.values.copy()\n",
        "    scaler2 = MinMaxScaler().fit(true_vals)\n",
        "    scaled_true_vales = scaler2.transform(true_vals)\n",
        "    scaled_test_vales = scaler2.transform(test_vals)\n",
        "    rmse = math.sqrt(mean_squared_error(scaled_true_vales, \n",
        "                                        scaled_test_vales))\n",
        "    rmses.append(rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "observed mae: 0.2617217162174475\n",
            "Test mae: 0.2617642375087819\n",
            "observed mae: 0.06435300333636668\n",
            "Test mae: 0.06411093746888656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot   sun  uree  NCS binar\n",
            "0   6.0  2.63  3.710000  4.57  ...   1.100890  8.49  16.1        0.0\n",
            "1   8.2  0.00  4.950000  4.36  ...   1.148492  9.67   7.5        0.0\n",
            "2  11.2  2.20  4.010000  4.80  ...   1.197351  8.27   7.3        0.0\n",
            "3   5.8  2.77  4.233865  4.36  ...   1.196362  8.69  16.1        1.0\n",
            "4  11.0  2.57  4.198679  4.59  ...   1.185410  8.57   9.5        1.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "observed mae: 0.24345194129456324\n",
            "Test mae: 0.24140620632244106\n",
            "observed mae: 0.06330294044138392\n",
            "Test mae: 0.06422688514971069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze  gras  lact  ...  gras prot   sun       uree  NCS binar\n",
            "0  11.700000  2.17  3.87  4.75  ...   1.382143  8.33   3.900000        0.0\n",
            "1   8.227348  3.14  4.41  4.13  ...   1.037647  9.06  26.700000        0.0\n",
            "2  11.000000  2.36  3.23  4.72  ...   1.117647  8.57  33.700000        0.0\n",
            "3  11.000000  2.10  5.15  4.67  ...   1.921642  8.09  20.133004        1.0\n",
            "4   8.000000  2.90  4.63  4.74  ...   1.258152  9.22  24.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "observed mae: 0.2461785437964436\n",
            "Test mae: 0.24507674505742255\n",
            "observed mae: 0.06482985792533762\n",
            "Test mae: 0.0649073883878365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze      gras      lact  ...  gras prot   sun       uree  NCS binar\n",
            "0   6.300000  0.00  2.420000  4.320000  ...   0.735562  8.47  28.000000        0.0\n",
            "1   8.271418  3.09  4.042247  4.630000  ...   1.132812  9.45  24.400000        0.0\n",
            "2   7.000839  2.69  4.214032  4.790000  ...   1.521994  8.79  19.992267        1.0\n",
            "3   5.000000  3.41  5.670000  4.545609  ...   1.186769  9.63  28.600000        1.0\n",
            "4  10.100000  2.56  2.900000  4.880000  ...   0.909091  8.90  13.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "observed mae: 0.21860669124369142\n",
            "Test mae: 0.21421721243433026\n",
            "observed mae: 0.06412764412495861\n",
            "Test mae: 0.06276656398768861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot      sun  uree  NCS binar\n",
            "0   5.7  3.35  6.940000  4.63  ...   1.648456  9.60000   8.1        1.0\n",
            "1   6.3  3.07  4.650000  4.99  ...   1.207792  9.45000  29.7        1.0\n",
            "2   6.5  0.00  3.860000  4.73  ...   1.099715  9.12000  13.0        0.0\n",
            "3   7.5  2.60  3.810000  5.06  ...   1.175926  9.00769  16.2        0.0\n",
            "4   8.0  2.56  4.017597  4.77  ...   1.154762  9.04000   9.3        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:67: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "observed mae: 0.20154831774091414\n",
            "Test mae: 0.19656294951191067\n",
            "observed mae: 0.06500459403988243\n",
            "Test mae: 0.06478828433086713\n",
            "   cant      caze  gras  lact  ...  gras prot    sun  uree  NCS binar\n",
            "0   7.2  3.070000  4.29  4.65  ...   1.120104   9.42  35.0        0.0\n",
            "1   7.4  0.000000  4.66  4.67  ...   1.219895   9.31  23.9        1.0\n",
            "2  13.4  2.282143  2.89  4.56  ...   0.894737   8.53  36.3        0.0\n",
            "3   3.6  3.430000  4.73  5.02  ...   1.075000  10.16   5.5        0.0\n",
            "4   5.0  2.410000  4.95  4.38  ...   1.581470   8.19  28.1        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXOyIjf6n20u",
        "colab_type": "code",
        "outputId": "3a8f1cb3-86d6-4a4c-ff33-377cc495a652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(rmses), np.std(rmses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.04799002261068887 0.0015991057431794897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_a6aJX6aDbA",
        "colab_type": "text"
      },
      "source": [
        "# VAE MCD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H0z51DCAuz9g",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "values = missing_encoded.values.copy()\n",
        "train, test, comp_train, comp_test = train_test_split(values,\n",
        "                                                      df_non_null.values.copy(),\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=LOCAL_SEED)\n",
        "scaler = MinMaxScaler().fit(train)\n",
        "x_train = scaler.transform(train)\n",
        "x_test = scaler.transform(test)\n",
        "n_dims = x_train.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eNCDt7r_aIxN",
        "colab": {}
      },
      "source": [
        "class VAEDropout:\n",
        "    def __init__(self, n_dims,\n",
        "                 recurrent_weight=0.5,\n",
        "                 optimizer=\"adam\",\n",
        "                 dropout_probability=0.5,\n",
        "                 hidden_activation=\"relu\",\n",
        "                 output_activation=\"sigmoid\",\n",
        "                 init=\"glorot_normal\",\n",
        "                 l2_penalty=1e-3,\n",
        "                 hidden_size=hidden_size):\n",
        "        self.n_dims = n_dims\n",
        "        self.recurrent_weight = recurrent_weight\n",
        "        self.optimizer = optimizer\n",
        "        self.dropout_probability = dropout_probability\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "        self.init = init\n",
        "        self.l2_penalty = l2_penalty\n",
        "        self.hidden_size = hidden_size\n",
        "        self._create_model()\n",
        "\n",
        "    def _create_model(self):\n",
        "        latent_dim = int(np.ceil(self.n_dims*0.5))\n",
        "        inputs = Input(shape=(2*n_dims, ), name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "        self.encoder = Model(inputs, [z_mean, \n",
        "                                      z_log_var], name='encoder')\n",
        "        latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init,\n",
        "                  kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                 init=self.init,\n",
        "                 kernel_regularizer=l2(self.l2_penalty),\n",
        "                  bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        outputs = Dense(self.n_dims, activation=self.output_activation,\n",
        "                        init=self.init,\n",
        "                       kernel_regularizer=l2(self.l2_penalty),\n",
        "                        bias_regularizer=l2(self.l2_penalty))(x)\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs)[0]) # Just take the mean\n",
        "        self.model = Model(inputs, outputs, \n",
        "                           name='vae_mlp')\n",
        "        reconstruction_loss = self.make_vae_reconstruction_loss(n_dims, \n",
        "                                                       z_mean, \n",
        "                                                       z_log_var)\n",
        "        self.model.compile(optimizer=self.optimizer, \n",
        "                           loss=reconstruction_loss)\n",
        "\n",
        "    def make_vae_reconstruction_loss(self, n_features, z_mean, z_log_var):\n",
        "        def reconstruction_loss(input_and_mask, y_pred):\n",
        "            X_values = input_and_mask[:, :n_features]\n",
        "        \n",
        "            missing_mask = input_and_mask[:, n_features:]\n",
        "            observed_mask = 1 - missing_mask\n",
        "            X_values_observed = X_values * observed_mask\n",
        "            pred_observed = y_pred * observed_mask\n",
        "            reconstruction_loss = binary_crossentropy(y_true=X_values_observed, \n",
        "                                        y_pred=pred_observed)\n",
        "            reconstruction_loss*=n_features\n",
        "            kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "            kl_loss = K.sum(kl_loss, axis=-1)\n",
        "            kl_loss *= -0.5\n",
        "            vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "            return vae_loss\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def fill(self, data, missing_mask):\n",
        "        data[missing_mask] = -1\n",
        "        return data\n",
        "\n",
        "    def _create_missing_mask(self, data):\n",
        "        if data.dtype != \"f\" and data.dtype != \"d\":\n",
        "            data = data.astype(float)\n",
        "        return np.isnan(data)\n",
        "\n",
        "    def predict(self, x_test_with_mask):\n",
        "        predict_stochastic = K.function([self.decoder.layers[0].input,\n",
        "                                        K.learning_phase()],\n",
        "                                        [self.decoder.layers[-1].output])\n",
        "        latent_input = self.encoder.predict(x_test_with_mask)[0]\n",
        "        outputs = np.array([np.array(predict_stochastic([latent_input,\n",
        "                                                         1])).reshape((x_test_with_mask.shape[0],\n",
        "                                                                                     x_test_with_mask.shape[1]//2)) for _ in range(50)])\n",
        "        return np.mean(outputs, axis=0)\n",
        "\n",
        "    def _train_epoch(self, data, missing_mask, batch_size):\n",
        "        input_with_mask = np.hstack([data, missing_mask])\n",
        "        n_samples = len(input_with_mask)\n",
        "        n_batches = int(np.ceil(n_samples / batch_size))\n",
        "        indices = np.arange(n_samples)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = input_with_mask[indices]\n",
        "        for batch_idx in range(n_batches):\n",
        "            batch_start = batch_idx * batch_size\n",
        "            batch_end = (batch_idx + 1) * batch_size\n",
        "            batch_data = X_shuffled[batch_start:batch_end, :]\n",
        "            self.model.train_on_batch(batch_data, batch_data)\n",
        "        return self.model.predict(input_with_mask)\n",
        "\n",
        "    def train(self, x_train, x_test, batch_size=256, train_epochs=100):\n",
        "        missing_mask = self._create_missing_mask(x_train)\n",
        "        x_train = self.fill(x_train, missing_mask)\n",
        "        x_test_missing_mask = self._create_missing_mask(x_test) \n",
        "        x_test = self.fill(x_test, x_test_missing_mask)\n",
        "        observed_mask = ~missing_mask\n",
        "        x_test_observed_mask = ~x_test_missing_mask\n",
        "        for epoch in range(train_epochs):\n",
        "            X_pred = self._train_epoch(x_train, missing_mask, batch_size)\n",
        "            x_test_with_mask = np.hstack([x_test, x_test_missing_mask])\n",
        "            X_test_pred = self.predict(x_test_with_mask)\n",
        "            observed_mae = masked_mae(X_true=x_train,\n",
        "                                      X_pred=X_pred,\n",
        "                                      mask=observed_mask)\n",
        "            test_observed_mae = masked_mae(X_true=x_test,\n",
        "                                X_pred = X_test_pred,\n",
        "                                mask=x_test_observed_mask)\n",
        "            if epoch % 50 == 0:\n",
        "                print(\"Traing observed mae:\", observed_mae)\n",
        "                print(\"Test observed mae:\", test_observed_mae)\n",
        "            old_weight = (1.0 - self.recurrent_weight)\n",
        "            x_train[missing_mask] *= old_weight\n",
        "            x_test[x_test_missing_mask] *= old_weight\n",
        "            pred_missing = X_pred[missing_mask]\n",
        "            x_test_pred_missing = X_test_pred[x_test_missing_mask]\n",
        "            x_train[missing_mask] += self.recurrent_weight * pred_missing\n",
        "            x_test[x_test_missing_mask] += self.recurrent_weight*x_test_pred_missing\n",
        "        return x_train.copy(), x_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c50e44a7-d036-4f99-fdde-c1fcd61c7e29",
        "id": "bQcfK0I6wFwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "seeds = [LOCAL_SEED+2, LOCAL_SEED+1, LOCAL_SEED+4, LOCAL_SEED+6, LOCAL_SEED+8]\n",
        "rmses = []\n",
        "cols = df_non_null.columns\n",
        "non_null_values = df_non_null.values.copy()\n",
        "for seed_number in seeds:\n",
        "    values = missing_encoded.values.copy()\n",
        "    train, test, comp_train, comp_test = train_test_split(values.copy(),\n",
        "                                                        non_null_values.copy(),\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=seed_number)\n",
        "    df_test_complete = pd.DataFrame(columns=cols, \n",
        "                                    data=comp_test.copy())\n",
        "    scaler = MinMaxScaler().fit(train)\n",
        "    x_train = scaler.transform(train)\n",
        "    x_test = scaler.transform(test)\n",
        "    n_dims = x_train.shape[1]\n",
        "    aedropout = VAEDropout(n_dims=n_dims)\n",
        "    complete_encoded = aedropout.train(x_train.copy(), \n",
        "                                    x_test.copy(), \n",
        "                                    train_epochs=n_epochs,\n",
        "                                    batch_size=n_batch_size)\n",
        "    train_encoded, test_encoded = complete_encoded\n",
        "    missing_cols = list(missing_encoded)\n",
        "    inverse_test_encoded = scaler.inverse_transform(test_encoded)\n",
        "    df_test_dummies = pd.DataFrame(columns=missing_cols, \n",
        "                                   data=inverse_test_encoded)\n",
        "    df_test_dummies = reverse_encoding(df_test_dummies.copy())\n",
        "    df_test_dummies.drop(cat_cols, axis=1,\n",
        "                         inplace=True)\n",
        "    df_test_complete.drop(cat_cols, axis=1,\n",
        "                          inplace=True)\n",
        "    true_vals = df_test_complete.values.copy()\n",
        "    test_vals = df_test_dummies.values.copy()\n",
        "    scaler2 = MinMaxScaler().fit(true_vals)\n",
        "    scaled_true_vales = scaler2.transform(true_vals)\n",
        "    scaled_test_vales = scaler2.transform(test_vals)\n",
        "    rmse = math.sqrt(mean_squared_error(scaled_true_vales, \n",
        "                                        scaled_test_vales))\n",
        "    rmses.append(rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.22660911977275913\n",
            "Test observed mae: 0.22531270232303727\n",
            "Traing observed mae: 0.036607300745461244\n",
            "Test observed mae: 0.036820914448346544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot   sun  uree  NCS binar\n",
            "0   6.0  2.63  3.710000  4.57  ...   1.100890  8.49  16.1        0.0\n",
            "1   8.2  0.00  4.950000  4.36  ...   1.148492  9.67   7.5        0.0\n",
            "2  11.2  2.20  4.010000  4.80  ...   1.184630  8.27   7.3        0.0\n",
            "3   5.8  2.77  4.291581  4.36  ...   1.174942  8.69  16.1        1.0\n",
            "4  11.0  2.57  4.046769  4.59  ...   1.185410  8.57   9.5        1.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.24886417266699817\n",
            "Test observed mae: 0.24727365970526735\n",
            "Traing observed mae: 0.04366566089960063\n",
            "Test observed mae: 0.04416542304850564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze  gras  lact  ...  gras prot   sun       uree  NCS binar\n",
            "0  11.700000  2.17  3.87  4.75  ...   1.382143  8.33   3.900000        0.0\n",
            "1   5.591596  3.14  4.41  4.13  ...   1.037647  9.06  26.700000        0.0\n",
            "2  11.000000  2.36  3.23  4.72  ...   1.117647  8.57  33.700000        0.0\n",
            "3  11.000000  2.10  5.15  4.67  ...   1.921642  8.09  18.536514        1.0\n",
            "4   8.000000  2.90  4.63  4.74  ...   1.258152  9.22  24.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.2519431198443704\n",
            "Test observed mae: 0.2517121552289873\n",
            "Traing observed mae: 0.036492242590507956\n",
            "Test observed mae: 0.0378104743295788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze      gras      lact  ...  gras prot   sun      uree  NCS binar\n",
            "0   6.300000  0.00  2.420000  4.320000  ...   0.735562  8.47  28.00000        0.0\n",
            "1   6.815742  3.09  4.223087  4.630000  ...   1.132812  9.45  24.40000        0.0\n",
            "2   8.579557  2.69  3.823060  4.790000  ...   1.521994  8.79  32.03881        1.0\n",
            "3   5.000000  3.41  5.670000  4.513451  ...   1.088976  9.63  28.60000        1.0\n",
            "4  10.100000  2.56  2.900000  4.880000  ...   0.909091  8.90  13.90000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.25284541918704284\n",
            "Test observed mae: 0.25058595693299685\n",
            "Traing observed mae: 0.03612812295254475\n",
            "Test observed mae: 0.03553275835305286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot       sun  uree  NCS binar\n",
            "0   5.7  3.35  6.940000  4.63  ...   1.648456  9.600000   8.1        1.0\n",
            "1   6.3  3.07  4.650000  4.99  ...   1.207792  9.450000  29.7        1.0\n",
            "2   6.5  0.00  3.860000  4.73  ...   1.099715  9.120000  13.0        0.0\n",
            "3   7.5  2.60  3.810000  5.06  ...   1.175926  8.917086  16.2        0.0\n",
            "4   8.0  2.56  4.148563  4.77  ...   1.154762  9.040000   9.3        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"sigmoid\", kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg..., kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.23455197377072015\n",
            "Test observed mae: 0.23349151702541465\n",
            "Traing observed mae: 0.035773413910223116\n",
            "Test observed mae: 0.0359704733719995\n",
            "   cant      caze  gras  lact  ...  gras prot    sun  uree  NCS binar\n",
            "0   7.2  3.070000  4.29  4.65  ...   1.120104   9.42  35.0        0.0\n",
            "1   7.4  0.000000  4.66  4.67  ...   1.219895   9.31  23.9        1.0\n",
            "2  13.4  2.302931  2.89  4.56  ...   0.894737   8.53  36.3        0.0\n",
            "3   3.6  3.430000  4.73  5.02  ...   1.075000  10.16   5.5        0.0\n",
            "4   5.0  2.410000  4.95  4.38  ...   1.581470   8.19  28.1        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "da69f22a-2bec-4282-f16e-c7c170270f6e",
        "id": "b49P0TAwwFwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(rmses), np.std(rmses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.04655965742248365 0.0012359338368721727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8y6VKVBMqyPB"
      },
      "source": [
        "# AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Lirje8sqyPP",
        "colab": {}
      },
      "source": [
        "def masked_mae(X_true, X_pred, mask):\n",
        "    masked_diff = X_true[mask] - X_pred[mask]\n",
        "    return np.mean(np.abs(masked_diff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GqmNdU0Lu1Bi",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "values = missing_encoded.values.copy()\n",
        "train, test, comp_train, comp_test = train_test_split(values,\n",
        "                                                      df_non_null.values.copy(),\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=LOCAL_SEED)\n",
        "scaler = MinMaxScaler().fit(train)\n",
        "x_train = scaler.transform(train)\n",
        "x_test = scaler.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dcd8G7YAqyPX",
        "colab": {}
      },
      "source": [
        "class Autoencoder:\n",
        "    def __init__(self, n_dims,\n",
        "                 recurrent_weight=0.5,\n",
        "                 optimizer=\"adam\",\n",
        "                 dropout_probability=0.1,\n",
        "                 hidden_activation=\"relu\",\n",
        "                 output_activation=\"sigmoid\",\n",
        "                 init=\"glorot_normal\",\n",
        "                 l1_penalty=0,\n",
        "                 l2_penalty=1e-3,\n",
        "                 hidden_size=hidden_size):\n",
        "        self.n_dims = n_dims\n",
        "        self.recurrent_weight = recurrent_weight\n",
        "        self.optimizer = optimizer\n",
        "        self.dropout_probability = dropout_probability\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "        self.init = init\n",
        "        self.l1_penalty = l1_penalty\n",
        "        self.l2_penalty = l2_penalty\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def make_reconstruction_loss(self, n_features):\n",
        "    \n",
        "        def reconstruction_loss(input_and_mask, y_pred):\n",
        "            X_values = input_and_mask[:, :n_features]\n",
        "            missing_mask = input_and_mask[:, n_features:]\n",
        "            observed_mask = 1 - missing_mask\n",
        "            X_values_observed = X_values * observed_mask\n",
        "            pred_observed = y_pred * observed_mask\n",
        "            return binary_crossentropy(y_true=X_values_observed, \n",
        "                                       y_pred=pred_observed)\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def _create_model(self):\n",
        "        latent_dim = int(np.ceil(self.n_dims*0.5))\n",
        "        inputs = Input(shape=(2*n_dims, ), name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        encoded = Dense(latent_dim, name='encoding')(x)\n",
        "        self.encoder = Model(inputs, encoded, name='encoder')\n",
        "        latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        outputs = Dense(n_dims, activation=self.output_activation)(x)\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs))\n",
        "        self.model = Model(inputs, outputs, name='vae_mlp')\n",
        "        loss_function = self.make_reconstruction_loss(n_dims)\n",
        "        self.model.compile(optimizer=self.optimizer, \n",
        "                           loss=loss_function)\n",
        "\n",
        "    def fill(self, data, missing_mask):\n",
        "        data[missing_mask] = -1\n",
        "        return data\n",
        "\n",
        "    def _create_missing_mask(self, data):\n",
        "        if data.dtype != \"f\" and data.dtype != \"d\":\n",
        "            data = data.astype(float)\n",
        "\n",
        "        return np.isnan(data)\n",
        "\n",
        "    def _train_epoch(self, data, missing_mask, batch_size):\n",
        "        input_with_mask = np.hstack([data, missing_mask])\n",
        "        n_samples = len(input_with_mask)\n",
        "        n_batches = int(np.ceil(n_samples / batch_size))\n",
        "        indices = np.arange(n_samples)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = input_with_mask[indices]\n",
        "        for batch_idx in range(n_batches):\n",
        "            batch_start = batch_idx * batch_size\n",
        "            batch_end = (batch_idx + 1) * batch_size\n",
        "            batch_data = X_shuffled[batch_start:batch_end, :]\n",
        "            self.model.train_on_batch(batch_data, batch_data)\n",
        "        return self.model.predict(input_with_mask)\n",
        "\n",
        "    def train(self, x_train, x_test, batch_size=256, train_epochs=100):\n",
        "        missing_mask = self._create_missing_mask(x_train)\n",
        "        x_train = self.fill(x_train, missing_mask)\n",
        "        x_test_missing_mask = self._create_missing_mask(x_test) \n",
        "        x_test = self.fill(x_test, x_test_missing_mask)\n",
        "        self._create_model()\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.model.summary()\n",
        "        observed_mask = ~missing_mask\n",
        "        x_test_observed_mask = ~x_test_missing_mask\n",
        "        input_with_mask = np.hstack([x_train, missing_mask])\n",
        "        for epoch in range(train_epochs):\n",
        "            X_pred = self._train_epoch(x_train, missing_mask, batch_size)\n",
        "            x_test_with_mask = np.hstack([x_test, x_test_missing_mask])\n",
        "            X_test_pred = self.model.predict(x_test_with_mask)\n",
        "            observed_mae = masked_mae(X_true=x_train,\n",
        "                                    X_pred=X_pred,\n",
        "                                    mask=observed_mask)\n",
        "            test_observed_mae = masked_mae(X_true=x_test,\n",
        "                                           X_pred = X_test_pred,\n",
        "                                           mask=x_test_observed_mask)\n",
        "            if epoch % 50 == 0:\n",
        "                print(\"observed mae:\", observed_mae)\n",
        "                print(\"Test mae:\", test_observed_mae)\n",
        "\n",
        "            old_weight = (1.0 - self.recurrent_weight)\n",
        "            x_train[missing_mask] *= old_weight\n",
        "            x_test[x_test_missing_mask] *= old_weight\n",
        "            pred_missing = X_pred[missing_mask]\n",
        "            x_test_pred_missing = X_test_pred[x_test_missing_mask]\n",
        "            x_train[missing_mask] += self.recurrent_weight * pred_missing\n",
        "            x_test[x_test_missing_mask] += self.recurrent_weight * x_test_pred_missing\n",
        "        return x_train.copy(), x_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIBD1Zo2wSUY",
        "outputId": "5ed282eb-183c-49d7-9117-8090702357b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "seeds = [LOCAL_SEED+2, LOCAL_SEED+1, LOCAL_SEED+4, LOCAL_SEED+6, LOCAL_SEED+8]\n",
        "rmses = []\n",
        "cols = df_non_null.columns\n",
        "non_null_values = df_non_null.values.copy()\n",
        "for seed_number in seeds:\n",
        "    values = missing_encoded.values.copy()\n",
        "    train, test, comp_train, comp_test = train_test_split(values.copy(),\n",
        "                                                        non_null_values.copy(),\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=seed_number)\n",
        "    df_test_complete = pd.DataFrame(columns=cols, \n",
        "                                    data=comp_test.copy())\n",
        "    scaler = MinMaxScaler().fit(train)\n",
        "    x_train = scaler.transform(train)\n",
        "    x_test = scaler.transform(test)\n",
        "    n_dims = x_train.shape[1]\n",
        "    aedropout = Autoencoder(n_dims=n_dims)\n",
        "    complete_encoded = aedropout.train(x_train.copy(), \n",
        "                                    x_test.copy(), \n",
        "                                    train_epochs=n_epochs,\n",
        "                                    batch_size=n_batch_size)\n",
        "    train_encoded, test_encoded = complete_encoded\n",
        "    missing_cols = list(missing_encoded)\n",
        "    inverse_test_encoded = scaler.inverse_transform(test_encoded)\n",
        "    df_test_dummies = pd.DataFrame(columns=missing_cols, \n",
        "                                   data=inverse_test_encoded)\n",
        "    df_test_dummies = reverse_encoding(df_test_dummies.copy())\n",
        "    df_test_dummies.drop(cat_cols, axis=1,\n",
        "                         inplace=True)\n",
        "    df_test_complete.drop(cat_cols, axis=1,\n",
        "                          inplace=True)\n",
        "    true_vals = df_test_complete.values.copy()\n",
        "    test_vals = df_test_dummies.values.copy()\n",
        "    scaler2 = MinMaxScaler().fit(true_vals)\n",
        "    scaled_true_vales = scaler2.transform(true_vals)\n",
        "    scaled_test_vales = scaler2.transform(test_vals)\n",
        "    rmse = math.sqrt(mean_squared_error(scaled_true_vales, \n",
        "                                        scaled_test_vales))\n",
        "    rmses.append(rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 1000)              25000     \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 6)                 1506      \n",
            "=================================================================\n",
            "Total params: 276,756\n",
            "Trainable params: 276,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 250)               1750      \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1000)              251000    \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 264,762\n",
            "Trainable params: 264,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 6)                 276756    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 12)                264762    \n",
            "=================================================================\n",
            "Total params: 541,518\n",
            "Trainable params: 541,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "observed mae: 0.15413524577154586\n",
            "Test mae: 0.15270720617754807\n",
            "observed mae: 0.013302105834224488\n",
            "Test mae: 0.013498818617466815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot   sun  uree  NCS binar\n",
            "0   6.0  2.63  3.710000  4.57  ...   1.100890  8.49  16.1        0.0\n",
            "1   8.2  0.00  4.950000  4.36  ...   1.148492  9.67   7.5        0.0\n",
            "2  11.2  2.20  4.010000  4.80  ...   1.430167  8.27   7.3        0.0\n",
            "3   5.8  2.77  2.691558  4.36  ...   0.744866  8.69  16.1        1.0\n",
            "4  11.0  2.57  3.823616  4.59  ...   1.185410  8.57   9.5        1.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 1000)              25000     \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 6)                 1506      \n",
            "=================================================================\n",
            "Total params: 276,756\n",
            "Trainable params: 276,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 250)               1750      \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1000)              251000    \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 264,762\n",
            "Trainable params: 264,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 6)                 276756    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 12)                264762    \n",
            "=================================================================\n",
            "Total params: 541,518\n",
            "Trainable params: 541,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "observed mae: 0.15194173214052806\n",
            "Test mae: 0.152538189038154\n",
            "observed mae: 0.013586226425265881\n",
            "Test mae: 0.014200845677798984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "       cant  caze  gras  lact  ...  gras prot   sun       uree  NCS binar\n",
            "0  11.70000  2.17  3.87  4.75  ...   1.382143  8.33   3.900000        0.0\n",
            "1   6.21388  3.14  4.41  4.13  ...   1.037647  9.06  26.700000        0.0\n",
            "2  11.00000  2.36  3.23  4.72  ...   1.117647  8.57  33.700000        0.0\n",
            "3  11.00000  2.10  5.15  4.67  ...   1.921642  8.09  16.927547        1.0\n",
            "4   8.00000  2.90  4.63  4.74  ...   1.258152  9.22  24.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1000)              25000     \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 6)                 1506      \n",
            "=================================================================\n",
            "Total params: 276,756\n",
            "Trainable params: 276,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 250)               1750      \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 1000)              251000    \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 264,762\n",
            "Trainable params: 264,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 6)                 276756    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 12)                264762    \n",
            "=================================================================\n",
            "Total params: 541,518\n",
            "Trainable params: 541,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "observed mae: 0.15193507620534225\n",
            "Test mae: 0.15307196236919976\n",
            "observed mae: 0.012516779906154851\n",
            "Test mae: 0.0129998533951316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze      gras      lact  ...  gras prot   sun       uree  NCS binar\n",
            "0   6.300000  0.00  2.420000  4.320000  ...   0.735562  8.47  28.000000        1.0\n",
            "1   6.566512  3.09  4.521131  4.630000  ...   1.132812  9.45  24.400000        0.0\n",
            "2   8.011668  2.69  4.808068  4.790000  ...   1.521994  8.79   6.751478        1.0\n",
            "3   5.000000  3.41  5.670000  4.446279  ...   1.303050  9.63  28.600000        1.0\n",
            "4  10.100000  2.56  2.900000  4.880000  ...   0.909091  8.90  13.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 1000)              25000     \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 6)                 1506      \n",
            "=================================================================\n",
            "Total params: 276,756\n",
            "Trainable params: 276,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 250)               1750      \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1000)              251000    \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 264,762\n",
            "Trainable params: 264,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 6)                 276756    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 12)                264762    \n",
            "=================================================================\n",
            "Total params: 541,518\n",
            "Trainable params: 541,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "observed mae: 0.1669991614240924\n",
            "Test mae: 0.1669434737013913\n",
            "observed mae: 0.013638229392688645\n",
            "Test mae: 0.01335230004346148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot       sun  uree  NCS binar\n",
            "0   5.7  3.35  6.940000  4.63  ...   1.648456  9.600000   8.1        1.0\n",
            "1   6.3  3.07  4.650000  4.99  ...   1.207792  9.450000  29.7        1.0\n",
            "2   6.5  0.00  3.860000  4.73  ...   1.099715  9.120000  13.0        0.0\n",
            "3   7.5  2.60  3.810000  5.06  ...   1.175926  9.018045  16.2        0.0\n",
            "4   8.0  2.56  3.895984  4.77  ...   1.154762  9.040000   9.3        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 1000)              25000     \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 250)               250250    \n",
            "_________________________________________________________________\n",
            "dropout_62 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 6)                 1506      \n",
            "=================================================================\n",
            "Total params: 276,756\n",
            "Trainable params: 276,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "z_sampling (InputLayer)      (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 250)               1750      \n",
            "_________________________________________________________________\n",
            "dropout_63 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1000)              251000    \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 12)                12012     \n",
            "=================================================================\n",
            "Total params: 264,762\n",
            "Trainable params: 264,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"vae_mlp\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 6)                 276756    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 12)                264762    \n",
            "=================================================================\n",
            "Total params: 541,518\n",
            "Trainable params: 541,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "observed mae: 0.15627640767806647\n",
            "Test mae: 0.1544388987550376\n",
            "observed mae: 0.011807706839847009\n",
            "Test mae: 0.01178807479763114\n",
            "   cant      caze  gras  lact  ...  gras prot    sun  uree  NCS binar\n",
            "0   7.2  3.070000  4.29  4.65  ...   1.120104   9.42  35.0        0.0\n",
            "1   7.4  0.000000  4.66  4.67  ...   1.219895   9.31  23.9        1.0\n",
            "2  13.4  0.003657  2.89  4.56  ...   0.894737   8.53  36.3        0.0\n",
            "3   3.6  3.430000  4.73  5.02  ...   1.075000  10.16   5.5        0.0\n",
            "4   5.0  2.410000  4.95  4.38  ...   1.581470   8.19  28.1        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y5oLdvWAwSUh",
        "outputId": "27a778f2-c598-4fdb-8976-c72cb17c82ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(rmses), np.std(rmses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.053652362168770826 0.0011674074651310039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PjJ4ap2drgQk"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKt8DFgzu2Ha",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "values = missing_encoded.values.copy()\n",
        "train, test, comp_train, comp_test = train_test_split(values,\n",
        "                                                      df_non_null.values.copy(),\n",
        "                                                      test_size=0.1,\n",
        "                                                      random_state=LOCAL_SEED)\n",
        "scaler = MinMaxScaler().fit(train)\n",
        "x_train = scaler.transform(train)\n",
        "x_test = scaler.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZF_5mh_ergRf",
        "colab": {}
      },
      "source": [
        "class VAE:\n",
        "\n",
        "    def __init__(self, n_dims,\n",
        "                 recurrent_weight=0.5,\n",
        "                 optimizer=\"adam\",\n",
        "                 dropout_probability=0.1,\n",
        "                 hidden_activation=\"relu\",\n",
        "                 output_activation=\"sigmoid\",\n",
        "                 init=\"glorot_normal\",\n",
        "                 l2_penalty=1e-3):\n",
        "        self.n_dims = n_dims\n",
        "        self.recurrent_weight = recurrent_weight\n",
        "        self.optimizer = optimizer\n",
        "        self.dropout_probability = dropout_probability\n",
        "        self.hidden_activation = hidden_activation\n",
        "        self.output_activation = output_activation\n",
        "        self.init = init\n",
        "        self.l2_penalty = l2_penalty\n",
        "        self.hidden_size = hidden_size\n",
        "        self._create_model()\n",
        "\n",
        "    def make_reconstruction_loss(self, n_features, z_mean, z_log_var):\n",
        "        def reconstruction_loss(input_and_mask, y_pred):\n",
        "            X_values = input_and_mask[:, :n_features]\n",
        "            missing_mask = input_and_mask[:, n_features:]\n",
        "            observed_mask = 1 - missing_mask\n",
        "            X_values_observed = X_values * observed_mask\n",
        "            pred_observed = y_pred * observed_mask\n",
        "            reconstruction_loss = binary_crossentropy(y_true=X_values_observed, \n",
        "                                        y_pred=pred_observed)\n",
        "            reconstruction_loss*=n_features\n",
        "            kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "            kl_loss = K.sum(kl_loss, axis=-1)\n",
        "            kl_loss *= -0.5\n",
        "            vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "            return vae_loss\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def sampling(self, args):\n",
        "        \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "        # Arguments\n",
        "            args (tensor): mean and log of variance of Q(z|X)\n",
        "        # Returns\n",
        "            z (tensor): sampled latent vector\n",
        "        \"\"\"\n",
        "    \n",
        "        z_mean, z_log_var = args\n",
        "        batch = K.shape(z_mean)[0]\n",
        "        dim = K.int_shape(z_mean)[1]\n",
        "        # by default, random_normal has mean = 0 and std = 1.0\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def _create_model(self):\n",
        "        latent_dim = (int(np.ceil(self.n_dims*0.5)))\n",
        "        inputs = Input(shape=(2*self.n_dims, ), name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "        z = Lambda(self.sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "        self.encoder = Model(inputs, [z_mean, \n",
        "                                      z_log_var, z], name='encoder')\n",
        "        latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(self.hidden_size//4, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        x = Dense(self.hidden_size, activation=self.hidden_activation,\n",
        "                  init=self.init)(x)\n",
        "        x = Dropout(self.dropout_probability)(x)\n",
        "        outputs = Dense(self.n_dims, activation=self.output_activation)(x)\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs)[2])\n",
        "        self.model = Model(inputs, outputs, \n",
        "                           name='vae_mlp')\n",
        "        reconstruction_loss = self.make_reconstruction_loss(n_dims, \n",
        "                                                       z_mean, \n",
        "                                                       z_log_var)\n",
        "        self.model.compile(optimizer=self.optimizer, \n",
        "                           loss=reconstruction_loss)\n",
        "\n",
        "    def fill(self, data, missing_mask):\n",
        "        data[missing_mask] = -1\n",
        "        return data\n",
        "\n",
        "    def _create_missing_mask(self, data):\n",
        "        if data.dtype != \"f\" and data.dtype != \"d\":\n",
        "            data = data.astype(float)\n",
        "        return np.isnan(data)\n",
        "\n",
        "    def _train_epoch(self, data, missing_mask, batch_size):\n",
        "        input_with_mask = np.hstack([data, missing_mask])\n",
        "        n_samples = len(input_with_mask)\n",
        "        n_batches = int(np.ceil(n_samples / batch_size))\n",
        "        indices = np.arange(n_samples)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = input_with_mask[indices]\n",
        "        for batch_idx in range(n_batches):\n",
        "            batch_start = batch_idx * batch_size\n",
        "            batch_end = (batch_idx + 1) * batch_size\n",
        "            batch_data = X_shuffled[batch_start:batch_end, :]\n",
        "            self.model.train_on_batch(batch_data, batch_data)\n",
        "        return self.model.predict(input_with_mask)\n",
        "\n",
        "    def train(self, x_train, x_test, batch_size=256, train_epochs=100):\n",
        "        missing_mask = self._create_missing_mask(x_train)\n",
        "        x_train = self.fill(x_train, missing_mask)\n",
        "        x_test_missing_mask = self._create_missing_mask(x_test) \n",
        "        x_test = self.fill(x_test, x_test_missing_mask)\n",
        "        observed_mask = ~missing_mask\n",
        "        x_test_observed_mask = ~x_test_missing_mask\n",
        "        for epoch in range(train_epochs):\n",
        "            X_pred = self._train_epoch(x_train, missing_mask, batch_size)\n",
        "            x_test_with_mask = np.hstack([x_test, x_test_missing_mask])\n",
        "            X_test_pred = self.model.predict(x_test_with_mask)\n",
        "            observed_mae = masked_mae(X_true=x_train,\n",
        "                                      X_pred=X_pred,\n",
        "                                      mask=observed_mask)\n",
        "            test_observed_mae = masked_mae(X_true=x_test,\n",
        "                                X_pred = X_test_pred,\n",
        "                                mask=x_test_observed_mask)\n",
        "            if epoch % 50 == 0:\n",
        "                print(\"Traing observed mae:\", observed_mae)\n",
        "                print(\"Test observed mae:\", test_observed_mae)\n",
        "            old_weight = (1.0 - self.recurrent_weight)\n",
        "            x_train[missing_mask] *= old_weight\n",
        "            x_test[x_test_missing_mask] *= old_weight\n",
        "            pred_missing = X_pred[missing_mask]\n",
        "            x_test_pred_missing = X_test_pred[x_test_missing_mask]\n",
        "            x_train[missing_mask] += self.recurrent_weight * pred_missing\n",
        "            x_test[x_test_missing_mask] += self.recurrent_weight*x_test_pred_missing\n",
        "        return x_train.copy(), x_test.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWfdwedcwYO0",
        "outputId": "8d929acd-667c-4b33-9571-f87797d8cf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "seeds = [LOCAL_SEED+2, LOCAL_SEED+1, LOCAL_SEED+4, LOCAL_SEED+6, LOCAL_SEED+8]\n",
        "rmses = []\n",
        "cols = df_non_null.columns\n",
        "non_null_values = df_non_null.values.copy()\n",
        "for seed_number in seeds:\n",
        "    values = missing_encoded.values.copy()\n",
        "    train, test, comp_train, comp_test = train_test_split(values.copy(),\n",
        "                                                        non_null_values.copy(),\n",
        "                                                        test_size=0.1,\n",
        "                                                        random_state=seed_number)\n",
        "    df_test_complete = pd.DataFrame(columns=cols, \n",
        "                                    data=comp_test.copy())\n",
        "    scaler = MinMaxScaler().fit(train)\n",
        "    x_train = scaler.transform(train)\n",
        "    x_test = scaler.transform(test)\n",
        "    n_dims = x_train.shape[1]\n",
        "    aedropout = VAE(n_dims=n_dims)\n",
        "    complete_encoded = aedropout.train(x_train.copy(), \n",
        "                                    x_test.copy(), \n",
        "                                    train_epochs=n_epochs,\n",
        "                                    batch_size=n_batch_size)\n",
        "    train_encoded, test_encoded = complete_encoded\n",
        "    missing_cols = list(missing_encoded)\n",
        "    inverse_test_encoded = scaler.inverse_transform(test_encoded)\n",
        "    df_test_dummies = pd.DataFrame(columns=missing_cols, \n",
        "                                   data=inverse_test_encoded)\n",
        "    df_test_dummies = reverse_encoding(df_test_dummies.copy())\n",
        "    df_test_dummies.drop(cat_cols, axis=1,\n",
        "                         inplace=True)\n",
        "    df_test_complete.drop(cat_cols, axis=1,\n",
        "                          inplace=True)\n",
        "    true_vals = df_test_complete.values.copy()\n",
        "    test_vals = df_test_dummies.values.copy()\n",
        "    scaler2 = MinMaxScaler().fit(true_vals)\n",
        "    scaled_true_vales = scaler2.transform(true_vals)\n",
        "    scaled_test_vales = scaler2.transform(test_vals)\n",
        "    rmse = math.sqrt(mean_squared_error(scaled_true_vales, \n",
        "                                        scaled_test_vales))\n",
        "    rmses.append(rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traing observed mae: 0.16350777180873072\n",
            "Test observed mae: 0.16245265955786237\n",
            "Traing observed mae: 0.07598858026285693\n",
            "Test observed mae: 0.0748460094404927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot   sun  uree  NCS binar\n",
            "0   6.0  2.63  3.710000  4.57  ...   1.100890  8.49  16.1        0.0\n",
            "1   8.2  0.00  4.950000  4.36  ...   1.148492  9.67   7.5        1.0\n",
            "2  11.2  2.20  4.010000  4.80  ...   1.173728  8.27   7.3        0.0\n",
            "3   5.8  2.77  4.155094  4.36  ...   1.168003  8.69  16.1        1.0\n",
            "4  11.0  2.57  4.158092  4.59  ...   1.185410  8.57   9.5        1.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Traing observed mae: 0.15704283454404988\n",
            "Test observed mae: 0.15723342707768861\n",
            "Traing observed mae: 0.07465064473810831\n",
            "Test observed mae: 0.07554457790408228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze  gras  lact  ...  gras prot   sun       uree  NCS binar\n",
            "0  11.700000  2.17  3.87  4.75  ...   1.382143  8.33   3.900000        0.0\n",
            "1   7.967963  3.14  4.41  4.13  ...   1.037647  9.06  26.700000        0.0\n",
            "2  11.000000  2.36  3.23  4.72  ...   1.117647  8.57  33.700000        0.0\n",
            "3  11.000000  2.10  5.15  4.67  ...   1.921642  8.09  20.496801        1.0\n",
            "4   8.000000  2.90  4.63  4.74  ...   1.258152  9.22  24.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Traing observed mae: 0.16017735594203944\n",
            "Test observed mae: 0.16029746634231765\n",
            "Traing observed mae: 0.0747324532973126\n",
            "Test observed mae: 0.0754732137437987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        cant  caze      gras      lact  ...  gras prot   sun       uree  NCS binar\n",
            "0   6.300000  0.00  2.420000  4.320000  ...   0.735562  8.47  28.000000        0.0\n",
            "1   7.997450  3.09  4.059078  4.630000  ...   1.132812  9.45  24.400000        0.0\n",
            "2   7.530432  2.69  4.106957  4.790000  ...   1.521994  8.79  20.296407        1.0\n",
            "3   5.000000  3.41  5.670000  4.582116  ...   1.171007  9.63  28.600000        1.0\n",
            "4  10.100000  2.56  2.900000  4.880000  ...   0.909091  8.90  13.900000        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Traing observed mae: 0.16041209106984128\n",
            "Test observed mae: 0.16032672410467447\n",
            "Traing observed mae: 0.07440845189196567\n",
            "Test observed mae: 0.07165096295621076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(250, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1000, activation=\"relu\", kernel_initializer=\"glorot_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   cant  caze      gras  lact  ...  gras prot       sun  uree  NCS binar\n",
            "0   5.7  3.35  6.940000  4.63  ...   1.648456  9.600000   8.1        1.0\n",
            "1   6.3  3.07  4.650000  4.99  ...   1.207792  9.450000  29.7        1.0\n",
            "2   6.5  0.00  3.860000  4.73  ...   1.099715  9.120000  13.0        0.0\n",
            "3   7.5  2.60  3.810000  5.06  ...   1.175926  9.038527  16.2        0.0\n",
            "4   8.0  2.56  4.097641  4.77  ...   1.154762  9.040000   9.3        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n",
            "Traing observed mae: 0.15992955915318058\n",
            "Test observed mae: 0.1582801608662896\n",
            "Traing observed mae: 0.07519406968192512\n",
            "Test observed mae: 0.07572679354713605\n",
            "   cant      caze  gras  lact  ...  gras prot    sun  uree  NCS binar\n",
            "0   7.2  3.070000  4.29  4.65  ...   1.120104   9.42  35.0        0.0\n",
            "1   7.4  0.000000  4.66  4.67  ...   1.219895   9.31  23.9        1.0\n",
            "2  13.4  2.208197  2.89  4.56  ...   0.894737   8.53  36.3        0.0\n",
            "3   3.6  3.430000  4.73  5.02  ...   1.075000  10.16   5.5        0.0\n",
            "4   5.0  2.410000  4.95  4.38  ...   1.581470   8.19  28.1        0.0\n",
            "\n",
            "[5 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkbPrsxFwYO8",
        "outputId": "872bb96d-6e97-49ab-ec41-4d64a7c6eb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.mean(rmses), np.std(rmses))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.047273312094549345 0.0015688243471892547\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}